{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import resample\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import usefulFunctions as useful\n",
    "import eval_functions as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = \"Master_PL.xlsx - Master_PL.csv\"\n",
    "normalized_table = pd.read_csv(fileName, header=0, \n",
    "                    names=[\"id\", \"type\", \"gender\", \"age\", \"monthsFromScreening\", \"protein_BL\", \"protein_V4\",\n",
    "                          \"protein_V6\", \"protein_V8\", \"protein_V10\", \"protein_V12\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>monthsFromScreening</th>\n",
       "      <th>protein_BL</th>\n",
       "      <th>protein_V4</th>\n",
       "      <th>protein_V6</th>\n",
       "      <th>protein_V8</th>\n",
       "      <th>protein_V10</th>\n",
       "      <th>protein_V12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3069</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3073</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3074</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3085</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3087</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3109</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3151</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3161</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3169</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3200</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3222</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3257</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3270</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>83.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>99.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3271</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3301</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3320</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>46.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3353</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3355</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3357</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3358</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3361</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3362</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>4056</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>4057</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>4058</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>4065</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>4070</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>4076</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>4078</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>4081</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>4082</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>4091</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>4092</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>4094</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>4101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>4102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>59.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>4106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>4107</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>4108</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>4109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>4110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>4111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>4114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>4115</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>74.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>4117</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>4121</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>4122</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>116.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>4123</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>4124</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>4125</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>4135</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  type  gender  age  monthsFromScreening  protein_BL  protein_V4  \\\n",
       "0    3011     1       2   32                  NaN        26.0         NaN   \n",
       "1    3016     1       2   58                  NaN        66.0       67.00   \n",
       "2    3069     1       1   54                  NaN        24.0       34.00   \n",
       "3    3072     1       1   47                  NaN        44.0       55.00   \n",
       "4    3073     1       2   48                  NaN        68.0       64.00   \n",
       "5    3074     1       2   31                  NaN        40.0       42.00   \n",
       "6    3085     1       2   57                  NaN        55.0       52.00   \n",
       "7    3087     1       2   57                  NaN        45.0       50.00   \n",
       "8    3109     1       2   53                  NaN        37.0       52.00   \n",
       "9    3151     1       2   57                  NaN         NaN         NaN   \n",
       "10   3161     1       2   44                  NaN         NaN         NaN   \n",
       "11   3165     1       1   59                  NaN         NaN         NaN   \n",
       "12   3169     1       2   57                  NaN         NaN         NaN   \n",
       "13   3200     1       2   55                  NaN        46.0       47.00   \n",
       "14   3206     1       1   31                  NaN        23.0       23.00   \n",
       "15   3216     1       1   52                  NaN        34.0       42.00   \n",
       "16   3222     1       2   57                  NaN        47.0       52.00   \n",
       "17   3257     1       1   54                  NaN        35.0       31.00   \n",
       "18   3270     1       2   54                  NaN        73.0       83.00   \n",
       "19   3271     1       2   58                  NaN        70.0       80.00   \n",
       "20   3276     1       1   55                  NaN        33.0         NaN   \n",
       "21   3300     1       2   52                  NaN        69.0       75.00   \n",
       "22   3301     1       2   53                  NaN        40.0       36.00   \n",
       "23   3320     1       2   56                  NaN        37.0       37.00   \n",
       "24   3353     1       1   56                  NaN        28.0       34.00   \n",
       "25   3355     1       2   33                  NaN        21.0       20.00   \n",
       "26   3357     1       2   44                  NaN        25.0       28.00   \n",
       "27   3358     1       2   49                  NaN        27.0       31.00   \n",
       "28   3361     1       1   56                  NaN        47.0       42.00   \n",
       "29   3362     1       1   42                  NaN        30.0       30.00   \n",
       "..    ...   ...     ...  ...                  ...         ...         ...   \n",
       "589  4056     2       2   64                  1.0        49.0       52.00   \n",
       "590  4057     2       2   61                  2.0        40.0       38.00   \n",
       "591  4058     2       2   62                  1.0        60.0       67.00   \n",
       "592  4065     2       1   62                  6.0        33.0       35.00   \n",
       "593  4070     2       1   80                 20.0        38.0       28.00   \n",
       "594  4075     2       1   60                  2.0        36.0         NaN   \n",
       "595  4076     2       2   73                  4.0        40.0       37.00   \n",
       "596  4078     2       2   70                  2.0        58.0         NaN   \n",
       "597  4081     2       2   72                 15.0         0.5        0.56   \n",
       "598  4082     2       2   65                  3.0         0.7        0.75   \n",
       "599  4091     2       1   68                 14.0        24.0       23.00   \n",
       "600  4092     2       1   77                  1.0        22.0       20.00   \n",
       "601  4094     2       1   77                  5.0        37.0         NaN   \n",
       "602  4101     2       1   66                  2.0        39.0       42.00   \n",
       "603  4102     2       2   68                  1.0        70.0       59.00   \n",
       "604  4106     2       2   71                  2.0        39.0       44.00   \n",
       "605  4107     2       2   70                  0.0        48.0         NaN   \n",
       "606  4108     2       2   66                  3.0        49.0       53.00   \n",
       "607  4109     2       2   68                  3.0        23.0       27.00   \n",
       "608  4110     2       2   71                  2.0        47.0       44.00   \n",
       "609  4111     2       2   74                  2.0        84.0       80.00   \n",
       "610  4114     2       2   67                  2.0        38.0       45.00   \n",
       "611  4115     2       2   67                  2.0        74.0       70.00   \n",
       "612  4117     2       1   60                  1.0        21.0       21.00   \n",
       "613  4121     2       1   66                 12.0        36.0       33.00   \n",
       "614  4122     2       2   64                  3.0        99.0      116.00   \n",
       "615  4123     2       1   61                  3.0        38.0       42.00   \n",
       "616  4124     2       2   71                  2.0        33.0       35.00   \n",
       "617  4125     2       2   64                  0.0        74.0         NaN   \n",
       "618  4135     2       2   67                 12.0         3.0       44.00   \n",
       "\n",
       "     protein_V6  protein_V8  protein_V10  protein_V12  \n",
       "0           NaN         NaN          NaN          NaN  \n",
       "1         70.00       56.00          NaN          NaN  \n",
       "2         32.00       30.00         33.0          NaN  \n",
       "3         37.00         NaN         40.0         37.0  \n",
       "4         77.00         NaN         65.0         79.0  \n",
       "5         43.00       44.00         43.0          NaN  \n",
       "6         48.00       57.00          NaN          NaN  \n",
       "7           NaN         NaN          NaN          NaN  \n",
       "8         41.00       48.00         41.0          NaN  \n",
       "9           NaN         NaN          NaN          NaN  \n",
       "10          NaN         NaN          NaN          NaN  \n",
       "11          NaN         NaN          NaN          NaN  \n",
       "12          NaN         NaN          NaN          NaN  \n",
       "13        53.00       49.00         48.0         52.0  \n",
       "14          NaN         NaN          NaN          NaN  \n",
       "15        41.00       41.00         48.0         57.0  \n",
       "16        47.00       65.00         67.0          NaN  \n",
       "17          NaN         NaN          NaN          NaN  \n",
       "18        60.00        0.72         99.0         92.0  \n",
       "19          NaN         NaN          NaN          NaN  \n",
       "20          NaN         NaN          NaN          NaN  \n",
       "21        67.00       71.00         70.0         73.0  \n",
       "22        41.00         NaN         38.0         47.0  \n",
       "23        41.00       35.00         46.7          NaN  \n",
       "24        36.00         NaN          NaN          NaN  \n",
       "25        22.00       19.00          NaN         16.0  \n",
       "26        29.00       21.00         21.0         25.0  \n",
       "27        27.00       25.00          NaN          NaN  \n",
       "28        49.00       41.00         41.0         44.0  \n",
       "29        36.00       29.00         24.0         30.0  \n",
       "..          ...         ...          ...          ...  \n",
       "589       56.00       53.00         60.0          NaN  \n",
       "590       46.00       39.00         45.0          NaN  \n",
       "591       63.00       67.00          NaN          NaN  \n",
       "592         NaN         NaN          NaN          NaN  \n",
       "593       25.00       39.00          NaN          NaN  \n",
       "594         NaN         NaN          NaN          NaN  \n",
       "595       36.00       42.00          NaN          NaN  \n",
       "596       63.00         NaN          NaN          NaN  \n",
       "597         NaN        0.56          NaN          NaN  \n",
       "598        0.78        0.94          NaN          NaN  \n",
       "599       24.00       22.00         27.0          NaN  \n",
       "600       25.00       22.00         28.0          NaN  \n",
       "601       45.00       40.00         44.0          NaN  \n",
       "602       39.00       45.00          NaN          NaN  \n",
       "603       55.00       57.00          NaN          NaN  \n",
       "604       60.00       52.00          NaN          NaN  \n",
       "605         NaN         NaN          NaN          NaN  \n",
       "606       52.00       49.00          NaN          NaN  \n",
       "607       25.00       21.00          NaN          NaN  \n",
       "608       43.00       46.00          NaN          NaN  \n",
       "609       67.00       67.00          NaN          NaN  \n",
       "610       34.00         NaN          NaN          NaN  \n",
       "611       66.00       74.00          NaN          NaN  \n",
       "612       18.00       24.00          NaN          NaN  \n",
       "613         NaN       42.00          NaN          NaN  \n",
       "614       96.00         NaN          NaN          NaN  \n",
       "615       39.00       56.00          NaN          NaN  \n",
       "616       33.00       46.00          NaN          NaN  \n",
       "617       75.00         NaN          NaN          NaN  \n",
       "618       67.00       42.00          NaN          NaN  \n",
       "\n",
       "[619 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_binary(x):\n",
    "    return x-1\n",
    "\n",
    "def make_boolean(x):\n",
    "    if x:\n",
    "        return bool(x)\n",
    "    else:\n",
    "        return bool(x)\n",
    "def standardize(x, mean, std):\n",
    "    return (x - mean)/std\n",
    "\n",
    "def support(column):\n",
    "    counts = defaultdict(int)\n",
    "    \n",
    "    for value in column:\n",
    "        counts[value]+=1\n",
    "    \n",
    "    for key in counts:\n",
    "        counts[key] = counts[key]/float(len(column))\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_table.type = normalized_table.type.apply(make_binary)\n",
    "normalized_table.gender = normalized_table.gender.apply(make_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_mean = np.mean(normalized_table.age)\n",
    "age_std = np.std(normalized_table.age)\n",
    "\n",
    "monthsFromScreening_mean = np.mean(normalized_table.monthsFromScreening)\n",
    "monthsFromScreening_std = np.std(normalized_table.monthsFromScreening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_table.age = normalized_table.age.apply(lambda x: standardize(x, age_mean, age_std))\n",
    "normalized_table.monthsFromScreening = normalized_table.monthsFromScreening.apply(lambda x: standardize(x, \n",
    "                                                                                             monthsFromScreening_mean,\\\n",
    "                                                                                             monthsFromScreening_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    190\n",
       "0     84\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_table = normalized_table[(normalized_table.protein_BL > 5) & (normalized_table.protein_V4 > 5) & (normalized_table.protein_V6 > 5) & \n",
    "             (normalized_table.protein_V8 > 5)]\n",
    "\n",
    "len(normalized_table)\n",
    "normalized_table.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_table = normalized_table[(normalized_table.protein_BL > 5) & (normalized_table.protein_V4 > 5) & (normalized_table.protein_V6 > 5) & \n",
    "             (normalized_table.protein_V8 > 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl_mean = np.mean(normalized_table.protein_BL)\n",
    "bl_std = np.std(normalized_table.protein_BL)\n",
    "\n",
    "v4_mean = np.mean(normalized_table.protein_V4)\n",
    "v4_std = np.std(normalized_table.protein_V4)\n",
    "\n",
    "v6_mean = np.mean(normalized_table.protein_V6)\n",
    "v6_std = np.std(normalized_table.protein_V6)\n",
    "\n",
    "v8_mean = np.mean(normalized_table.protein_V8)\n",
    "v8_std = np.std(normalized_table.protein_V8)\n",
    "\n",
    "v10_mean = np.mean(normalized_table.protein_V10)\n",
    "v10_std = np.std(normalized_table.protein_V10)\n",
    "\n",
    "v12_mean = np.mean(normalized_table.protein_V12)\n",
    "v12_std = np.std(normalized_table.protein_V12)\n",
    "\n",
    "normalized_table.protein_BL = normalized_table.protein_BL.apply(lambda x : standardize(x, bl_mean, bl_std))\n",
    "normalized_table.protein_V4 = normalized_table.protein_V4.apply(lambda x : standardize(x, v4_mean, v4_std))\n",
    "normalized_table.protein_V6 = normalized_table.protein_V6.apply(lambda x : standardize(x, v6_mean, v6_std))\n",
    "normalized_table.protein_V8 = normalized_table.protein_V8.apply(lambda x : standardize(x, v8_mean, v8_std))\n",
    "normalized_table.protein_V10 = normalized_table.protein_V10.apply(lambda x : standardize(x, v10_mean, v10_std))\n",
    "normalized_table.protein_V12 = normalized_table.protein_V12.apply(lambda x : standardize(x, v12_mean, v12_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    77\n",
      "0    33\n",
      "Name: type, dtype: int64\n",
      "1    76\n",
      "0    30\n",
      "Name: type, dtype: int64\n",
      "1    72\n",
      "0    28\n",
      "Name: type, dtype: int64\n",
      "1    76\n",
      "0    33\n",
      "Name: type, dtype: int64\n",
      "1    56\n",
      "0    24\n",
      "Name: type, dtype: int64\n",
      "1    22\n",
      "0    14\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(normalized_table[normalized_table[\"protein_BL\"] > 0].type.value_counts())\n",
    "print(normalized_table[normalized_table[\"protein_V4\"] > 0].type.value_counts())\n",
    "print(normalized_table[normalized_table[\"protein_V6\"] > 0].type.value_counts())\n",
    "print(normalized_table[normalized_table[\"protein_V8\"] > 0].type.value_counts())\n",
    "print(normalized_table[normalized_table[\"protein_V10\"] > 0].type.value_counts())\n",
    "print(normalized_table[normalized_table[\"protein_V12\"] > 0].type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    190\n",
       "0    190\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_majority = normalized_table[normalized_table.type==1]\n",
    "df_minority = normalized_table[normalized_table.type==0]\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=123)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "df_upsampled.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "53\n",
      "1    130\n",
      "0    130\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = normalized_table[['age', 'gender', 'protein_BL', 'protein_V4', 'protein_V6', 'protein_V8', 'type']]\n",
    "train = X.sample(frac=0.667,random_state=200)\n",
    "test = X.drop(train.index)\n",
    "\n",
    "X_test = test[['age', 'gender', 'protein_BL', 'protein_V4', 'protein_V6', 'protein_V8']].as_matrix()\n",
    "y_test = test[[\"type\"]].as_matrix()\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "\n",
    "df_majority = train[train.type == 1]\n",
    "print len(df_majority)\n",
    "df_minority = train[train.type == 0]\n",
    "print len(df_minority)\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=123)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "print df_upsampled.type.value_counts()\n",
    "X_train = df_upsampled[['age', 'gender', 'protein_BL', 'protein_V4', 'protein_V6', 'protein_V8']].as_matrix()\n",
    "y_train = df_upsampled[[\"type\"]].as_matrix()\n",
    "y_train = np.squeeze(y_train)\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "# # y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: type, dtype: int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# len(df_upsampled)\n",
    "# df_upsampled.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: type, dtype: int64)\n",
      "Series([], Name: type, dtype: int64)\n",
      "0    4\n",
      "1    1\n",
      "Name: type, dtype: int64\n",
      "Series([], Name: type, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(df_upsampled[df_upsampled.protein_BL > 5].type.value_counts())\n",
    "print(df_upsampled[df_upsampled.protein_V4 > 5].type.value_counts())\n",
    "print(df_upsampled[df_upsampled.protein_V6 > 5].type.value_counts())\n",
    "print(df_upsampled[df_upsampled.protein_V8 > 5].type.value_counts())\n",
    "print(df_upsampled[df_upsampled.protein_V10 > 5].type.value_counts())\n",
    "print(df_upsampled[df_upsampled.protein_V12 > 5].type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl_mean = np.mean(df_upsampled.protein_BL)\n",
    "bl_std = np.std(df_upsampled.protein_BL)\n",
    "\n",
    "v4_mean = np.mean(df_upsampled.protein_V4)\n",
    "v4_std = np.std(df_upsampled.protein_V4)\n",
    "\n",
    "v6_mean = np.mean(df_upsampled.protein_V6)\n",
    "v6_std = np.std(df_upsampled.protein_V6)\n",
    "\n",
    "v8_mean = np.mean(df_upsampled.protein_V8)\n",
    "v8_std = np.std(df_upsampled.protein_V8)\n",
    "\n",
    "v10_mean = np.mean(df_upsampled.protein_V10)\n",
    "v10_std = np.std(df_upsampled.protein_V10)\n",
    "\n",
    "v12_mean = np.mean(df_upsampled.protein_V12)\n",
    "v12_std = np.std(df_upsampled.protein_V12)\n",
    "\n",
    "df_upsampled.protein_BL = df_upsampled.protein_BL.apply(lambda x : standardize(x, bl_mean, bl_std))\n",
    "df_upsampled.protein_V4 = df_upsampled.protein_V4.apply(lambda x : standardize(x, v4_mean, v4_std))\n",
    "df_upsampled.protein_V6 = df_upsampled.protein_V6.apply(lambda x : standardize(x, v6_mean, v6_std))\n",
    "df_upsampled.protein_V8 = df_upsampled.protein_V8.apply(lambda x : standardize(x, v8_mean, v8_std))\n",
    "df_upsampled.protein_V10 = df_upsampled.protein_V10.apply(lambda x : standardize(x, v10_mean, v10_std))\n",
    "df_upsampled.protein_V12 = df_upsampled.protein_V12.apply(lambda x : standardize(x, v12_mean, v12_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl_model = ols('protein_BL ~ type', df_upsampled).fit()\n",
    "v4_model = ols('protein_V4 ~ type', df_upsampled).fit()\n",
    "v6_model = ols('protein_V6 ~ type', df_upsampled).fit()\n",
    "v8_model = ols('protein_V8 ~ type', df_upsampled).fit()\n",
    "v10_model = ols('protein_V10 ~ type', df_upsampled).fit()\n",
    "v12_model = ols('protein_V12 ~ type', df_upsampled).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             protein_BL   R-squared:                       0.017\n",
      "Model:                            OLS   Adj. R-squared:                  0.014\n",
      "Method:                 Least Squares   F-statistic:                     6.211\n",
      "Date:                Fri, 20 Oct 2017   Prob (F-statistic):             0.0131\n",
      "Time:                        15:20:14   Log-Likelihood:                -519.07\n",
      "No. Observations:                 368   AIC:                             1042.\n",
      "Df Residuals:                     366   BIC:                             1050.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1335      0.075     -1.791      0.074      -0.280       0.013\n",
      "type           0.2585      0.104      2.492      0.013       0.055       0.462\n",
      "==============================================================================\n",
      "Omnibus:                      131.883   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              627.452\n",
      "Skew:                           1.464   Prob(JB):                    5.63e-137\n",
      "Kurtosis:                       8.688   Cond. No.                         2.66\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(bl_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             protein_V4   R-squared:                       0.007\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     2.725\n",
      "Date:                Fri, 20 Oct 2017   Prob (F-statistic):             0.0997\n",
      "Time:                        15:20:15   Log-Likelihood:                -520.80\n",
      "No. Observations:                 368   AIC:                             1046.\n",
      "Df Residuals:                     366   BIC:                             1053.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.0888      0.075     -1.186      0.236      -0.236       0.058\n",
      "type           0.1720      0.104      1.651      0.100      -0.033       0.377\n",
      "==============================================================================\n",
      "Omnibus:                      560.453   Durbin-Watson:                   2.082\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           159809.836\n",
      "Skew:                           7.838   Prob(JB):                         0.00\n",
      "Kurtosis:                     103.879   Cond. No.                         2.66\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(v4_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             protein_V6   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     3.329\n",
      "Date:                Fri, 20 Oct 2017   Prob (F-statistic):             0.0689\n",
      "Time:                        15:20:15   Log-Likelihood:                -520.50\n",
      "No. Observations:                 368   AIC:                             1045.\n",
      "Df Residuals:                     366   BIC:                             1053.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.0981      0.075     -1.311      0.191      -0.245       0.049\n",
      "type           0.1900      0.104      1.825      0.069      -0.015       0.395\n",
      "==============================================================================\n",
      "Omnibus:                      548.523   Durbin-Watson:                   1.990\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           144297.784\n",
      "Skew:                           7.541   Prob(JB):                         0.00\n",
      "Kurtosis:                      98.829   Cond. No.                         2.66\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(v6_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             protein_V8   R-squared:                       0.014\n",
      "Model:                            OLS   Adj. R-squared:                  0.011\n",
      "Method:                 Least Squares   F-statistic:                     5.149\n",
      "Date:                Fri, 20 Oct 2017   Prob (F-statistic):             0.0238\n",
      "Time:                        15:20:16   Log-Likelihood:                -519.60\n",
      "No. Observations:                 368   AIC:                             1043.\n",
      "Df Residuals:                     366   BIC:                             1051.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1217      0.075     -1.630      0.104      -0.268       0.025\n",
      "type           0.2357      0.104      2.269      0.024       0.031       0.440\n",
      "==============================================================================\n",
      "Omnibus:                      190.582   Durbin-Watson:                   1.822\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1503.767\n",
      "Skew:                           2.043   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.021   Cond. No.                         2.66\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(v8_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            protein_V10   R-squared:                       0.024\n",
      "Model:                            OLS   Adj. R-squared:                  0.020\n",
      "Method:                 Least Squares   F-statistic:                     5.728\n",
      "Date:                Fri, 20 Oct 2017   Prob (F-statistic):             0.0175\n",
      "Time:                        15:20:16   Log-Likelihood:                -329.18\n",
      "No. Observations:                 234   AIC:                             662.4\n",
      "Df Residuals:                     232   BIC:                             669.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1620      0.094     -1.728      0.085      -0.347       0.023\n",
      "type           0.3107      0.130      2.393      0.017       0.055       0.567\n",
      "==============================================================================\n",
      "Omnibus:                      108.573   Durbin-Watson:                   1.890\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              954.063\n",
      "Skew:                           1.583   Prob(JB):                    6.73e-208\n",
      "Kurtosis:                      12.371   Cond. No.                         2.67\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(v10_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            protein_V12   R-squared:                       0.028\n",
      "Model:                            OLS   Adj. R-squared:                  0.020\n",
      "Method:                 Least Squares   F-statistic:                     3.465\n",
      "Date:                Fri, 20 Oct 2017   Prob (F-statistic):             0.0651\n",
      "Time:                        15:20:17   Log-Likelihood:                -169.96\n",
      "No. Observations:                 121   AIC:                             343.9\n",
      "Df Residuals:                     119   BIC:                             349.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1341      0.116     -1.160      0.248      -0.363       0.095\n",
      "type           0.3451      0.185      1.861      0.065      -0.022       0.712\n",
      "==============================================================================\n",
      "Omnibus:                      155.963   Durbin-Watson:                   2.022\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6431.765\n",
      "Skew:                           4.587   Prob(JB):                         0.00\n",
      "Kurtosis:                      37.519   Cond. No.                         2.44\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(v12_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_upsampled[['age', 'gender', 'protein_BL', 'protein_V4', 'protein_V6', 'protein_V8']].as_matrix()\n",
    "# X = df_upsampled[['age', 'gender']]\n",
    "# female_data = df_upsampled[df_upsampled['gender'] == 0]\n",
    "# male_data = df_upsampled[df_upsampled['gender'] == 1]\n",
    "# X = male_data[['age', 'protein_BL', 'protein_V4', 'protein_V6', 'protein_V8']].as_matrix()\n",
    "y = df_upsampled[['type']].as_matrix()\n",
    "# y = male_data[['type']].as_matrix()\n",
    "y = np.squeeze(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.333, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = linear_model.LogisticRegression()\n",
    "forest = RandomForestClassifier(n_estimators=30, random_state=1)\n",
    "ada_boost = AdaBoostClassifier(n_estimators=100, random_state=1)\n",
    "svclass = svm.SVC(probability=True, kernel='linear', degree=1, random_state=1, C=1)\n",
    "tree_clf = tree.DecisionTreeClassifier(min_samples_leaf=10)\n",
    "\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "# ada_boost.fit(X_train, y_train)\n",
    "# svclass.fit(X_train, y_train)\n",
    "# tree_clf.fit(X_train, y_train)\n",
    "clf = forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCKGiCBQhhBAqikARQgihon8Alyxv4zqIVlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1049e2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_info = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "auc_info = auc(roc_info[0], roc_info[1])\n",
    "useful.createROCGraph(roc_info[0], roc_info[1], auc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.81  0.19]\n",
      " [ 0.27  0.73]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEmCAYAAAD1FIKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104a7bf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, clf.predict(X_test))\n",
    "useful.plot_confusion_matrix(cm, [\"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1]),\n",
       " array([0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Fold Mean: 0.821, Cross Fold Stdev: 0.085\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "print(\"Cross Fold Mean: %.3f, Cross Fold Stdev: %.3f\" % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.772\n",
      "\n",
      "precision: \n",
      "\tall: ['0.754', '0.793']\n",
      "\tmicro: 0.772\n",
      "\tmacro: 0.773\n",
      "\tweighted: 0.773\n",
      "\t\n",
      "recall: \n",
      "\tall: ['0.812', '0.730']\n",
      "\tmicro: 0.772\n",
      "\tmacro: 0.771\n",
      "\tweighted: 0.772\n",
      "\t\n",
      "f1_measure: \n",
      "\tall: ['0.782', '0.760']\n",
      "\tmicro: 0.772\n",
      "\tmacro: 0.771\n",
      "\tweighted: 0.771\n",
      "\t\n",
      "support: \n",
      "\ty_true_dist: ['0.504', '0.496']\n",
      "\ty_true_count: 127.000\n",
      "\ty_predicted_dist: ['0.543', '0.457']\n",
      "\ty_predicted_count: 127.000\n",
      "\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = metrics.get_all_metrics(y_test, clf.predict(X_test))\n",
    "print(metrics.pretty_print_metrics(metrics_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18,  0.04,  0.25,  0.2 ,  0.16,  0.18])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(tree_clf, out_file=None, \n",
    "                         feature_names=['age', 'gender', 'protein_BL', 'protein_V4', 'protein_V6', 'protein_V8'],  \n",
    "                         class_names=[\"not_affected\", \"affected\"],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data, format='pdf')\n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Source.gv.pdf'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
